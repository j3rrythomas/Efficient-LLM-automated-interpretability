{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from neuron_explainer.activations.activations import load_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "      <th>explainer</th>\n",
       "      <th>NeuronViewer</th>\n",
       "      <th>Original</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Highlight</th>\n",
       "      <th>HighlightSummary</th>\n",
       "      <th>AVHS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>words related to comparison.</td>\n",
       "      <td>['assistant\\n\\ncited information related to th...</td>\n",
       "      <td>['assistant\\n\\ncommonality among comparisons.']</td>\n",
       "      <td>['assistant\\n\\nspecifically related content re...</td>\n",
       "      <td>['assistant\\n\\nconnotations used to describe s...</td>\n",
       "      <td>['assistant\\n\\ncomparisons or contrasts betwee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1838</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>phrases describing positions or situations in...</td>\n",
       "      <td>['assistant\\n\\nwords describing a recent or ol...</td>\n",
       "      <td>['assistant\\n\\nwords or phrases describing a f...</td>\n",
       "      <td>['assistant\\n\\ninstances of a particular socia...</td>\n",
       "      <td>['assistant\\n\\nidentifying emotional states of...</td>\n",
       "      <td>['assistant\\n\\nwords related to self-image.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>193</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>verbs indicating questioning or challenging be...</td>\n",
       "      <td>['assistant\\n\\nphrases or terms that have a ra...</td>\n",
       "      <td>['assistant\\n\\n statements that are direct cal...</td>\n",
       "      <td>['assistant\\n\\nanti-establishment or critical ...</td>\n",
       "      <td>['assistant\\n\\nconversational exchanges where ...</td>\n",
       "      <td>['assistant\\n\\nterms related to privilege and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1685</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>expressions of gratitude and agreeing to rece...</td>\n",
       "      <td>['assistant\\n\\ninformation on how to subscribe...</td>\n",
       "      <td>['assistant\\n\\nwords related to terms of servi...</td>\n",
       "      <td>[\"assistant\\n\\noccasional updates made by a go...</td>\n",
       "      <td>['assistant\\n\\nopt-out options or notification...</td>\n",
       "      <td>['assistant\\n\\nidentifying keywords that refer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>431</td>\n",
       "      <td>meta-llama/Llama-3.2-1B-Instruct</td>\n",
       "      <td>numbers related to time, dates, and measureme...</td>\n",
       "      <td>['assistant\\n\\nthe day of a major sporting eve...</td>\n",
       "      <td>['assistant\\n\\nidentifiers like IDs, times, an...</td>\n",
       "      <td>['assistant\\n\\nnames of people.']</td>\n",
       "      <td>['assistant\\n\\nidentifying and extracting spec...</td>\n",
       "      <td>['assistant\\n\\nreferences to dates, times, or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  layer  neuron                         explainer  \\\n",
       "0           0      0     286  meta-llama/Llama-3.2-1B-Instruct   \n",
       "1           1     10    1838  meta-llama/Llama-3.2-1B-Instruct   \n",
       "2           2     20     193  meta-llama/Llama-3.2-1B-Instruct   \n",
       "3           3     30    1685  meta-llama/Llama-3.2-1B-Instruct   \n",
       "4           4     40     431  meta-llama/Llama-3.2-1B-Instruct   \n",
       "\n",
       "                                        NeuronViewer  \\\n",
       "0                       words related to comparison.   \n",
       "1   phrases describing positions or situations in...   \n",
       "2  verbs indicating questioning or challenging be...   \n",
       "3   expressions of gratitude and agreeing to rece...   \n",
       "4   numbers related to time, dates, and measureme...   \n",
       "\n",
       "                                            Original  \\\n",
       "0  ['assistant\\n\\ncited information related to th...   \n",
       "1  ['assistant\\n\\nwords describing a recent or ol...   \n",
       "2  ['assistant\\n\\nphrases or terms that have a ra...   \n",
       "3  ['assistant\\n\\ninformation on how to subscribe...   \n",
       "4  ['assistant\\n\\nthe day of a major sporting eve...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0    ['assistant\\n\\ncommonality among comparisons.']   \n",
       "1  ['assistant\\n\\nwords or phrases describing a f...   \n",
       "2  ['assistant\\n\\n statements that are direct cal...   \n",
       "3  ['assistant\\n\\nwords related to terms of servi...   \n",
       "4  ['assistant\\n\\nidentifiers like IDs, times, an...   \n",
       "\n",
       "                                           Highlight  \\\n",
       "0  ['assistant\\n\\nspecifically related content re...   \n",
       "1  ['assistant\\n\\ninstances of a particular socia...   \n",
       "2  ['assistant\\n\\nanti-establishment or critical ...   \n",
       "3  [\"assistant\\n\\noccasional updates made by a go...   \n",
       "4                  ['assistant\\n\\nnames of people.']   \n",
       "\n",
       "                                    HighlightSummary  \\\n",
       "0  ['assistant\\n\\nconnotations used to describe s...   \n",
       "1  ['assistant\\n\\nidentifying emotional states of...   \n",
       "2  ['assistant\\n\\nconversational exchanges where ...   \n",
       "3  ['assistant\\n\\nopt-out options or notification...   \n",
       "4  ['assistant\\n\\nidentifying and extracting spec...   \n",
       "\n",
       "                                                AVHS  \n",
       "0  ['assistant\\n\\ncomparisons or contrasts betwee...  \n",
       "1      ['assistant\\n\\nwords related to self-image.']  \n",
       "2  ['assistant\\n\\nterms related to privilege and ...  \n",
       "3  ['assistant\\n\\nidentifying keywords that refer...  \n",
       "4  ['assistant\\n\\nreferences to dates, times, or ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIMULATOR_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"#\"gpt-3.5-turbo-instruct\"\n",
    "SIMULATOR_MODEL = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "INPUT_PATH = \"test_results/test_neurons_results_meta-llama--Llama-3.2-1B-Instruct.csv\"\n",
    "\n",
    "neuron_results_df = pd.read_csv(INPUT_PATH)\n",
    "neuron_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\\n\\nIt seems that the provided text does not contain any information about a space agency or a recent/old news event. The activations are mostly unknown or 0.\\n\\nLet's try with a different text:\\n\\nActivations: \\n<start>\\nNASA\\t10\\n is\\t0\\n planning\"]\n",
      "[\"\\n\\nIt seems that the previous response was not relevant to the question. Here's another attempt at the activation values for Neuron 4:\\n\\nActivations: \\n<start>\\n the\\tunknown\\n launch\\t10\\n of\\t0\\n a\\t0\\n new\\t0\\n rocket\\t\"]\n",
      "[\" for this neuron: none of the tokens were related to the space agency. \\n\\nLet's try a different document.\\n\\nActivations: \\n<start>\\nNASA\\t8\\n has\\t0\\n announced\\t0\\n the\\t0\\n discovery\\t0\\n of\\t0\\n water\\t0\"]\n",
      "[' but it seems the previous response was cut off. Here is a revised response for Neuron 4:\\n\\nActivations: \\n<start>\\nApollo\\t10\\n 17\\t9\\n was\\t7\\n a\\t6\\n final\\t5\\n mission\\t4\\n of\\t3\\n']\n",
      "[\"\\n\\nIt seems that the text provided doesn't contain any information about a space agency. I will provide the activation for a new text.\\n\\nActivations: \\n<start>\\n the\\t0\\n new\\t0\\n Artemis\\t10\\n mission\\t9\\n is\\t0\\n a\\t\"]\n",
      "[\"\\n\\nIt seems like the input for Neuron 4 was not relevant to the task. I'll try again with a new input.\\n\\nActivations: \\n<start>\\nNASA\\t6\\n is\\t0\\n launching\\t10\\n a\\t0\\n new\\t0\\n spacecraft\\t0\"]\n",
      "['\\n\\nIt appears that the input provided for Neuron 4 does not contain any relevant information about a space agency or a news event related to it. The input seems to be a quote or a passage about a different topic. As a result, the activations for Neuron 4 are']\n",
      "[\"\\n\\nIt appears that the provided text is not a coherent document. I'll provide the activation for a more coherent text:\\n\\nActivations: \\n<start>\\nthe\\tunknown\\n new\\tunknown\\n NASA\\tunknown\\n mission\\tunknown\\n to\\tunknown\\n mars\\tunknown\\n has\\t\"]\n",
      "[\"\\n\\nIt seems like the text given was not relevant to the topic of a space agency news event. Let's try with a different text.\\n\\n<start>\\n the\\t0\\n European\\t0\\n Space\\t10\\n Agency\\t8\\n has\\t0\\n announced\\t0\\n the\\t\"]\n",
      "['\\n\\nIt seems the input for Neuron 4 was not suitable. Let me try again with a new input.\\n\\nActivations: \\n<start>\\n the\\t0\\n Soviet\\t0\\n Union\\t0\\n launched\\t10\\n Luna\\t7\\n 2\\t5\\n,\\t']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'logprobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     simScore_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(neuron)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m modes:\n\u001b[0;32m---> 15\u001b[0m         simScore_results[mode]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mawait\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mget_score( row[mode], layer, neuron, SIMULATOR_MODEL))\n\u001b[1;32m     17\u001b[0m new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(simScore_results)\n\u001b[1;32m     18\u001b[0m new_df\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/Experiments/utils.py:208\u001b[0m, in \u001b[0;36mget_score\u001b[0;34m(explanation, layer, neuron, simulator_model)\u001b[0m\n\u001b[1;32m    196\u001b[0m valid_activation_records \u001b[38;5;241m=\u001b[39m neuron_record\u001b[38;5;241m.\u001b[39mvalid_activation_records(\n\u001b[1;32m    197\u001b[0m     activation_record_slice_params\u001b[38;5;241m=\u001b[39mslice_params\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    200\u001b[0m simulator \u001b[38;5;241m=\u001b[39m UncalibratedNeuronSimulator(\n\u001b[1;32m    201\u001b[0m     ExplanationNeuronSimulator(\n\u001b[1;32m    202\u001b[0m         SIMULATOR_MODEL_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m )\n\u001b[0;32m--> 208\u001b[0m scored_simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m simulate_and_score(simulator, valid_activation_records)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscored_simulation\u001b[38;5;241m.\u001b[39mget_preferred_score()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/scoring.py:137\u001b[0m, in \u001b[0;36msimulate_and_score\u001b[0;34m(simulator, activation_records)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimulate_and_score\u001b[39m(\n\u001b[1;32m    130\u001b[0m     simulator: NeuronSimulator,\n\u001b[1;32m    131\u001b[0m     activation_records: Sequence[ActivationRecord],\n\u001b[1;32m    132\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ScoredSimulation:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Score an explanation of a neuron by how well it predicts activations on the given text\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    sequences.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     scored_sequence_simulations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    139\u001b[0m             _simulate_and_score_sequence(\n\u001b[1;32m    140\u001b[0m                 simulator,\n\u001b[1;32m    141\u001b[0m                 activation_record,\n\u001b[1;32m    142\u001b[0m             )\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m activation_record \u001b[38;5;129;01min\u001b[39;00m activation_records\n\u001b[1;32m    144\u001b[0m         ]\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aggregate_scored_sequence_simulations(scored_sequence_simulations)\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/scoring.py:82\u001b[0m, in \u001b[0;36m_simulate_and_score_sequence\u001b[0;34m(simulator, activations)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_simulate_and_score_sequence\u001b[39m(\n\u001b[1;32m     79\u001b[0m     simulator: NeuronSimulator, activations: ActivationRecord\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ScoredSequenceSimulation:\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Score an explanation of a neuron by how well it predicts activations on a sentence.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m simulator\u001b[38;5;241m.\u001b[39msimulate(activations\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m     83\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(simulation)\n\u001b[1;32m     84\u001b[0m     rsquared_score \u001b[38;5;241m=\u001b[39m score_from_simulation(activations, simulation, rsquared_score_from_sequences)\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/calibrated_simulator.py:102\u001b[0m, in \u001b[0;36mCalibratedNeuronSimulator.simulate\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimulate\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SequenceSimulation:\n\u001b[0;32m--> 102\u001b[0m     uncalibrated_seq_simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muncalibrated_simulator\u001b[38;5;241m.\u001b[39msimulate(tokens)\n\u001b[1;32m    103\u001b[0m     calibrated_activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_calibration(\n\u001b[1;32m    104\u001b[0m         uncalibrated_seq_simulation\u001b[38;5;241m.\u001b[39mexpected_activations\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     calibrated_distribution_values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_calibration(dv) \u001b[38;5;28;01mfor\u001b[39;00m dv \u001b[38;5;129;01min\u001b[39;00m uncalibrated_seq_simulation\u001b[38;5;241m.\u001b[39mdistribution_values\n\u001b[1;32m    108\u001b[0m     ]\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/simulator.py:346\u001b[0m, in \u001b[0;36mExplanationNeuronSimulator.simulate\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    344\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mmake_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[1;32m    345\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse in score_explanation_by_activations is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response)\n\u001b[0;32m--> 346\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mparse_simulation_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in score_explanation_by_activations is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Efficient-LLM-automated-interpretability/neuron-explainer/neuron_explainer/explanations/simulator.py:209\u001b[0m, in \u001b[0;36mparse_simulation_response\u001b[0;34m(response, prompt_format, tokens)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnhandled prompt format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 209\u001b[0m response_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mchoice\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    210\u001b[0m choice[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    211\u001b[0m top_logprobs \u001b[38;5;241m=\u001b[39m choice[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'logprobs'"
     ]
    }
   ],
   "source": [
    "modes = [\"Original\", \"Summary\", \"Highlight\", \"HighlightSummary\", \"AVHS\"]\n",
    "simScore_results = {\"layer\":[], \"neuron\":[]}\n",
    "for mode in modes:\n",
    "    simScore_results[mode] = []\n",
    "\n",
    "for i, row in neuron_results_df.iterrows():\n",
    "    if i==0:\n",
    "        continue\n",
    "    layer = row[\"layer\"]\n",
    "    neuron = row[\"neuron\"]\n",
    "    simScore_results[\"layer\"].append(layer)\n",
    "    simScore_results[\"neuron\"].append(neuron)\n",
    "    \n",
    "    for mode in modes:\n",
    "        simScore_results[mode].append(await utils.get_score( row[mode], layer, neuron, SIMULATOR_MODEL))\n",
    "\n",
    "new_df = pd.DataFrame(simScore_results)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(INPUT_PATH.split(\".\")[0] + \"_score_\"+SIMULATOR_MODEL.replace(\"/\",\"--\")\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
